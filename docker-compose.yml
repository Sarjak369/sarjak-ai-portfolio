services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    command: ["ollama", "serve"]
    restart: unless-stopped

  # one-shot helper that pulls the model AFTER ollama is up
  ollama-pull:
    image: ollama/ollama:latest
    container_name: ollama-pull
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
    # wait until the server is answering, then pull model; ignore errors if pre-pulled
    entrypoint:
      [
        "/bin/sh",
        "-lc",
        "until ollama list >/dev/null 2>&1; do sleep 2; done; ollama pull qwen2.5:3b-instruct-q4_0 || true",
      ]
    restart: "no"

  app:
    build: .
    container_name: sarjak-portfolio
    environment:
      - LLM_PROVIDER=ollama
      - OLLAMA_BASE_URL=http://ollama:11434
      - PORT=7860
    ports:
      - "7860:7860"
    depends_on:
      - ollama
      - ollama-pull
    volumes:
      - ./chroma_db:/app/chroma_db
      - ./data:/app/data
    restart: unless-stopped

volumes:
  ollama:
